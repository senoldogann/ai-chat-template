# ğŸ› ï¸ Tools Entegrasyonu - Provider'lara NasÄ±l Entegre Edilir?

Bu dokÃ¼man, tools'larÄ±n her LLM provider'a nasÄ±l entegre edileceÄŸini aÃ§Ä±klar.

## ğŸ“‹ Genel BakÄ±ÅŸ

Tools'lar, AI'Ä±n native function calling yeteneklerini kullanarak doÄŸrudan fonksiyonlarÄ± Ã§aÄŸÄ±rmasÄ±na izin verir. Her provider'Ä±n kendi function calling format'Ä± vardÄ±r, ancak biz OpenAI format'Ä±nÄ± standart olarak kullanÄ±yoruz ve provider'a gÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz.

## ğŸ”„ Tools Entegrasyon AkÄ±ÅŸÄ±

### 1. Tools TanÄ±mlama (`lib/tools/index.ts`)

```typescript
export const TOOLS = {
  calculate: {
    name: 'calculate',
    description: 'Performs mathematical calculations',
    execute: async (args: { expression: string; precision?: number }) => {
      // Tool implementation
    },
  },
  // ... diÄŸer tools
};
```

### 2. Tools'u OpenAI Format'Ä±na Ã‡evirme (`app/api/chat/route.ts`)

```typescript
function convertToolsToFunctionFormat() {
  return [
    {
      type: 'function',
      function: {
        name: 'calculate',
        description: 'Performs mathematical calculations',
        parameters: {
          type: 'object',
          properties: {
            expression: { type: 'string', description: 'Math expression' },
            precision: { type: 'number', description: 'Decimal places' },
          },
          required: ['expression'],
        },
      },
    },
    // ... diÄŸer tools
  ];
}
```

### 3. Provider'a GÃ¶re Format DÃ¶nÃ¼ÅŸÃ¼mÃ¼

Her provider'Ä±n kendi function calling format'Ä± vardÄ±r:

#### OpenAI (OpenAI, OpenRouter, QrokCloud, GitHub Copilot)
- **Format**: OpenAI native format (direkt kullanÄ±labilir)
- **Parametre**: `tools` ve `tool_choice`
- **Ã–rnek**:
```typescript
{
  tools: [
    {
      type: 'function',
      function: {
        name: 'calculate',
        description: '...',
        parameters: { ... }
      }
    }
  ],
  tool_choice: 'auto'
}
```

#### Anthropic (Claude)
- **Format**: Anthropic native format (dÃ¶nÃ¼ÅŸtÃ¼rme gerekli)
- **Parametre**: `tools` (array of tool objects)
- **DÃ¶nÃ¼ÅŸÃ¼m**:
```typescript
const anthropicTools = request.tools?.map(tool => ({
  name: tool.function.name,
  description: tool.function.description,
  input_schema: tool.function.parameters,
}));
```

#### Google (Gemini)
- **Format**: Gemini native format (dÃ¶nÃ¼ÅŸtÃ¼rme gerekli)
- **Parametre**: `tools` (array with `function_declarations`)
- **DÃ¶nÃ¼ÅŸÃ¼m**:
```typescript
const geminiTools = request.tools ? [{
  function_declarations: request.tools.map(tool => ({
    name: tool.function.name,
    description: tool.function.description,
    parameters: tool.function.parameters,
  })),
}] : undefined;
```

#### Ollama
- **Format**: OpenAI-compatible (direkt kullanÄ±labilir)
- **Parametre**: `tools` ve `tool_choice`
- **Not**: Ollama'nÄ±n bazÄ± modelleri function calling destekler

#### Hugging Face
- **Format**: Model'e baÄŸlÄ± (Ã§oÄŸu model OpenAI format'Ä±nÄ± destekler)
- **Parametre**: Model'e gÃ¶re deÄŸiÅŸir
- **Not**: Qwen3-Omni gibi bazÄ± modeller function calling destekler

## ğŸ”§ Provider Implementation Ã–rnekleri

### OpenAI Provider (`lib/llm/providers/openai.ts`)

```typescript
async chat(request: LLMRequest): Promise<LLMResponse> {
  const response = await fetch(`${baseURL}/chat/completions`, {
    method: 'POST',
    body: JSON.stringify({
      model,
      messages: request.messages,
      temperature: request.temperature,
      max_tokens: request.max_tokens,
      // Tools direkt kullanÄ±labilir
      ...(request.tools && { tools: request.tools }),
      ...(request.tool_choice && { tool_choice: request.tool_choice }),
    }),
  });
}
```

### Anthropic Provider (`lib/llm/providers/anthropic.ts`)

```typescript
async chat(request: LLMRequest): Promise<LLMResponse> {
  // OpenAI format'Ä±nÄ± Anthropic format'Ä±na dÃ¶nÃ¼ÅŸtÃ¼r
  const anthropicTools = request.tools?.map(tool => ({
    name: tool.function.name,
    description: tool.function.description,
    input_schema: tool.function.parameters,
  }));

  const response = await fetch(`${baseURL}/messages`, {
    method: 'POST',
    body: JSON.stringify({
      model,
      messages: request.messages,
      temperature: request.temperature,
      max_tokens: request.max_tokens,
      // Anthropic format tools
      ...(anthropicTools && anthropicTools.length > 0 && { tools: anthropicTools }),
    }),
  });
}
```

### Google Provider (`lib/llm/providers/google.ts`)

```typescript
async chat(request: LLMRequest): Promise<LLMResponse> {
  // OpenAI format'Ä±nÄ± Gemini format'Ä±na dÃ¶nÃ¼ÅŸtÃ¼r
  const geminiTools = request.tools ? [{
    function_declarations: request.tools.map(tool => ({
      name: tool.function.name,
      description: tool.function.description,
      parameters: tool.function.parameters,
    })),
  }] : undefined;

  const response = await fetch(`${baseURL}/${model}:generateContent`, {
    method: 'POST',
    body: JSON.stringify({
      contents: request.messages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }],
      })),
      generationConfig: {
        temperature: request.temperature,
        maxOutputTokens: request.max_tokens,
      },
      // Gemini format tools
      ...(geminiTools && { tools: geminiTools }),
    }),
  });
}
```

## ğŸ“ Yeni Provider Eklerken

1. **LLMRequest interface'ini kontrol et**: `tools` ve `tool_choice` parametreleri var mÄ±?
2. **Provider'Ä±n function calling format'Ä±nÄ± Ã¶ÄŸren**: API dokÃ¼mantasyonuna bak
3. **Format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ekle**: OpenAI format'Ä±nÄ± provider format'Ä±na Ã§evir
4. **Test et**: Tools'larÄ±n doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrula

## ğŸ¯ Mevcut Durum

- âœ… **OpenAI**: Native function calling desteÄŸi eklendi
- âœ… **Anthropic**: Tools format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ eklendi
- âœ… **Google**: Tools format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ eklendi
- âš ï¸ **Ollama**: Model'e baÄŸlÄ± (Ã§oÄŸu model destekler)
- âš ï¸ **Hugging Face**: Model'e baÄŸlÄ± (Qwen3-Omni destekler)
- âš ï¸ **OpenRouter**: OpenAI format'Ä±nÄ± kullanÄ±r (direkt Ã§alÄ±ÅŸÄ±r)
- âš ï¸ **QrokCloud**: OpenAI format'Ä±nÄ± kullanÄ±r (direkt Ã§alÄ±ÅŸÄ±r)
- âš ï¸ **GitHub Copilot**: OpenAI format'Ä±nÄ± kullanÄ±r (direkt Ã§alÄ±ÅŸÄ±r)

## ğŸ”® Gelecek Ä°yileÅŸtirmeler

1. **Function Call Response Handling**: AI'dan gelen function call'larÄ± parse et ve execute et
2. **Multi-turn Function Calling**: Birden fazla function call'Ä± handle et
3. **Tool Result Formatting**: Tool sonuÃ§larÄ±nÄ± AI'Ä±n anlayabileceÄŸi formata Ã§evir
4. **Provider-specific Tool Limits**: Her provider'Ä±n tool limit'lerini handle et
5. **Tool Validation**: Tool parametrelerini validate et

## ğŸ“š Kaynaklar

- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [Anthropic Tools](https://docs.anthropic.com/claude/docs/tool-use)
- [Google Gemini Function Calling](https://ai.google.dev/docs/function_calling)
- [Ollama Function Calling](https://github.com/ollama/ollama/blob/main/docs/function-calling.md)

